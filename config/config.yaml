openai:
  api_key: ${OPENAI_API_KEY}

huggingface:
  api_key: ${HF_API_KEY}

paths:
  data_raw: './data/raw'
  data_processed: './data/processed'
  faiss_index: './models/faiss_index'
  faiss_metadata_json: './models/metadata.json'  # Added explicit metadata path
  llama2_ckpt: './models/llama2'
  flan_t5_ckpt: './models/flan_t5'

retrieval:
  embedding_model: 'sentence-transformers/all-MiniLM-L6-v2'
  top_k: 6

# Optional: Add model generation parameters
generation:
  flan_t5:
    max_length: 512
    temperature: 0.7
    do_sample: true
    top_p: 0.9
    repetition_penalty: 1.1

fine_tuning:
  llama2:
    model_name: "meta-llama/Llama-2-7b-hf"
    batch_size: 4
    grad_accum_steps: 4
    learning_rate: 5e-5
    epochs: 3
    lora_r: 8
    lora_alpha: 16
    lora_dropout: 0.05
    max_length: 512
    logging_steps: 20
  flan_t5:
    batch_size: 8
    learning_rate: 3e-5
    epochs: 3